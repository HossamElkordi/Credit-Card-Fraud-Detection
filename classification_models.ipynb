{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, Model\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('./Data/users.csv')\n",
    "cards = pd.read_csv('./Data/cards.csv')\n",
    "trans = pd.read_csv('./Data/transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_needed_cols = ['Current Age', 'Retirement Age', 'Gender', 'Zipcode', 'Per Capita Income - Zipcode', \n",
    "                    'Yearly Income - Person', 'Total Debt', 'FICO Score', 'Num Credit Cards']\n",
    "cards_needed_cols = ['User', 'CARD INDEX', 'Year PIN last Changed', 'Acct Open Date', 'Expires', 'Card Duration', \n",
    "                    'Has Chip', 'Cards Issued', 'Credit Limit', 'Visa', 'Mastercard', 'Discover', 'Amex', 'Debit', \n",
    "                    'Credit', 'Debit (Prepaid)']\n",
    "trans_needed_cols = ['User', 'Card', 'Time', 'Time From Now', 'Amount', 'Merchant Name', 'Merchant City', \n",
    "                    'Merchant State', 'Zip', 'MCC', 'Errors?', 'Swipe Transaction', 'Online Transaction', \n",
    "                    'Chip Transaction', 'Is Fraud?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_models = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Zip Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip = pd.concat([users.Zipcode, trans.Zip.fillna(0).astype(int)])\n",
    "zip_encoder = LabelEncoder()\n",
    "zip_encoder.fit_transform(zip)\n",
    "users.Zipcode = zip_encoder.transform(users.Zipcode)\n",
    "trans.Zip = zip_encoder.transform(trans.Zip.fillna(0).astype(int))\n",
    "data_prep_models['zip_encoder'] = zip_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 27247)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['Zipcode'].min(), users['Zipcode'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 27321)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['Zip'].min(), trans['Zip'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['Zipcode'] = users['Zipcode'].astype(np.uint16)\n",
    "trans['Zip'] = trans['Zip'].astype(np.uint16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling User Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Current Age       18\n",
       " Retirement Age    50\n",
       " dtype: int64,\n",
       " Current Age       101\n",
       " Retirement Age     79\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[['Current Age', 'Retirement Age']].min(), users[['Current Age', 'Retirement Age']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['Current Age'] = users['Current Age'].astype(np.uint8)\n",
    "users['Retirement Age'] = users['Retirement Age'].astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling User Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    1016\n",
       "Male       984\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_encoder = LabelEncoder()\n",
    "gender_encoder.fit_transform(users['Gender'])\n",
    "users['Gender'] = gender_encoder.transform(users['Gender'])\n",
    "data_prep_models['gender_encoder'] = gender_encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['Per Capita Income - Zipcode'] = users['Per Capita Income - Zipcode'].str.replace('$', '', regex=True).astype(int)\n",
    "users['Yearly Income - Person'] = users['Yearly Income - Person'].str.replace('$', '', regex=True).astype(int)\n",
    "users['Total Debt'] = users['Total Debt'].str.replace('$', '', regex=True).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling FICO Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 850)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['FICO Score'].min(), users['FICO Score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['FICO Score'] = users['FICO Score'].astype(np.uint16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling User's Credit Cards Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['Num Credit Cards'] = users['Num Credit Cards'].astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling User and Card Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards['User'] = cards['User'].astype(np.uint16)\n",
    "cards['CARD INDEX'] = cards['CARD INDEX'].astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Card Brand and Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Mastercard    3209\n",
       " Visa          2326\n",
       " Amex           402\n",
       " Discover       209\n",
       " Name: Card Brand, dtype: int64,\n",
       " Debit              3511\n",
       " Credit             2057\n",
       " Debit (Prepaid)     578\n",
       " Name: Card Type, dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards['Card Brand'].value_counts(), cards['Card Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Visa', 'Mastercard', 'Discover', 'Amex'], dtype=object),\n",
       " array(['Debit', 'Credit', 'Debit (Prepaid)'], dtype=object)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_brand_type_encoder = OneHotEncoder(categories=[cards['Card Brand'].unique(), cards['Card Type'].unique()], handle_unknown='ignore', dtype=np.uint8)\n",
    "brand = cards[['Card Brand', 'Card Type']]\n",
    "card_brand_type_encoder.fit_transform(brand)\n",
    "brand = pd.DataFrame(card_brand_type_encoder.transform(brand).toarray(), columns=['Visa', 'Mastercard', 'Discover', 'Amex', 'Debit', 'Credit', 'Debit (Prepaid)'])\n",
    "cards = pd.concat([cards.drop(columns=['Card Brand', 'Card Type']), brand], axis=1)\n",
    "data_prep_models['card_brand_type_encoder'] = card_brand_type_encoder\n",
    "card_brand_type_encoder.categories_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Has Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YES    5500\n",
       "NO      646\n",
       "Name: Has Chip, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards['Has Chip'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_chip_encoder = LabelEncoder()\n",
    "has_chip_encoder.fit_transform(cards['Has Chip'])\n",
    "cards['Has Chip'] = has_chip_encoder.transform(cards['Has Chip'])\n",
    "data_prep_models['has_chip_encoder'] = has_chip_encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Cards Issued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards['Cards Issued'].min(), cards['Cards Issued'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards['Cards Issued'] = cards['Cards Issued'].astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Card Credit Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards['Credit Limit'] = cards['Credit Limit'].str.replace('$', '', regex=True).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Cards Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.datetime.now()\n",
    "cards['Year PIN last Changed'] += (now.year - cards['Year PIN last Changed']).astype(np.uint16)\n",
    "cards['Expires'] = ((now - pd.to_datetime(cards['Expires'], infer_datetime_format=True)) / np.timedelta64(1, 'M')).astype(int)\n",
    "cards['Acct Open Date'] = ((now - pd.to_datetime(cards['Acct Open Date'], infer_datetime_format=True)) / np.timedelta64(1, 'M')).astype(int)\n",
    "cards['Card Duration'] = cards['Expires'] - cards['Acct Open Date']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction User and Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.sort_values(by=['User', 'Card', 'Year', 'Month', 'Day', 'Time'], inplace=True)\n",
    "trans['User'] = trans['User'].astype(np.uint16)\n",
    "trans['Card'] = trans['Card'].astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Date and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Time From Now'] = (now - pd.to_datetime(dict(year=trans['Year'], month=trans['Month'], day=trans['Day']))).dt.days\n",
    "trans['Time'] = trans['Time'].str.replace(':[0-9]+', '', regex=True).astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Amount'] = trans['Amount'].str.replace('$', '', regex=True).astype(float).apply(lambda x: np.log(max(1.0, x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Use Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Swipe Transaction', 'Online Transaction', 'Chip Transaction'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_chip_encoder = OneHotEncoder(categories=[list(trans['Use Chip'].unique())], handle_unknown='ignore', dtype=np.uint8)\n",
    "use_chip_encoder.fit_transform(trans[['Use Chip']])\n",
    "use_chip = pd.DataFrame(use_chip_encoder.transform(trans[['Use Chip']]).toarray(), columns=['Swipe Transaction', 'Online Transaction', 'Chip Transaction'])\n",
    "trans = pd.concat([trans.drop(columns=['Use Chip']), use_chip], axis=1)\n",
    "data_prep_models['use_chip_encoder'] = use_chip_encoder\n",
    "use_chip_encoder.categories_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Merchant City, State, Name and MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_name_encoder = LabelEncoder()\n",
    "merchant_name_encoder.fit(trans['Merchant Name'])\n",
    "trans['Merchant Name'] = merchant_name_encoder.transform(trans['Merchant Name'])\n",
    "data_prep_models['merchant_name_encoder'] = merchant_name_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100342)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['Merchant Name'].min(), trans['Merchant Name'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Merchant Name'] = trans['Merchant Name'].astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_city_encoder = LabelEncoder()\n",
    "merchant_city_encoder.fit(trans['Merchant City'])\n",
    "trans['Merchant City'] = merchant_city_encoder.transform(trans['Merchant City'])\n",
    "data_prep_models['merchant_city_encoder'] = merchant_city_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 13428)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['Merchant City'].min(), trans['Merchant City'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Merchant City'] = trans['Merchant City'].astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Merchant State'].fillna('Unknown', inplace=True)\n",
    "merchant_state_encoder = LabelEncoder()\n",
    "merchant_state_encoder.fit(trans['Merchant State'])\n",
    "trans['Merchant State'] = merchant_state_encoder.transform(trans['Merchant State'])\n",
    "data_prep_models['merchant_state_encoder'] = merchant_state_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 223)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['Merchant State'].min(), trans['Merchant State'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Merchant State'] = trans['Merchant State'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_encoder = LabelEncoder()\n",
    "mcc_encoder.fit(trans['MCC'])\n",
    "trans['MCC'] = mcc_encoder.transform(trans['MCC'])\n",
    "data_prep_models['mcc_encoder'] = mcc_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 108)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['MCC'].min(), trans['MCC'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Merchant State'] = trans['Merchant State'].astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Errors?'].fillna('No Errors', inplace=True)\n",
    "errors_encoder = LabelEncoder()\n",
    "errors_encoder.fit(trans['Errors?'])\n",
    "trans['Errors?'] = errors_encoder.transform(trans['Errors?'])\n",
    "data_prep_models['errors_encoder'] = errors_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 23)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans['Errors?'].min(), trans['Errors?'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Errors?'] = trans['Errors?'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['Is Fraud?'] = trans['Is Fraud?'].replace({'No': 0, 'Yes': 1}).astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data Prep Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Models/DataPrepModels.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(data_prep_models, './Models/DataPrepModels.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data/FinalData/types.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes = {}\n",
    "dtypes['users'] = users[users_needed_cols].dtypes.to_dict()\n",
    "dtypes['cards'] = cards[cards_needed_cols].dtypes.to_dict()\n",
    "dtypes['trans'] = trans[trans_needed_cols].dtypes.to_dict()\n",
    "joblib.dump(dtypes, './Data/FinalData/types.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[users_needed_cols].to_csv('./Data/FinalData/users.csv', index=False)\n",
    "cards[cards_needed_cols].to_csv('./Data/FinalData/cards.csv', index=False)\n",
    "trans[trans_needed_cols].to_csv('./Data/FinalData/trans.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = joblib.load('./Data/FinalData/types.pkl')\n",
    "\n",
    "users_needed_cols = ['Current Age', 'Retirement Age', 'Gender', 'Zipcode', 'Per Capita Income - Zipcode', \n",
    "                    'Yearly Income - Person', 'Total Debt', 'FICO Score', 'Num Credit Cards']\n",
    "cards_needed_cols = ['User', 'CARD INDEX', 'Year PIN last Changed', 'Acct Open Date', 'Expires', 'Card Duration', \n",
    "                    'Has Chip', 'Cards Issued', 'Credit Limit', 'Visa', 'Mastercard', 'Discover', 'Amex', 'Debit', \n",
    "                    'Credit', 'Debit (Prepaid)']\n",
    "trans_needed_cols = ['User', 'Card', 'Time', 'Time From Now', 'Amount', 'Merchant Name', 'Merchant City', \n",
    "                    'Merchant State', 'Zip', 'MCC', 'Errors?', 'Swipe Transaction', 'Online Transaction', \n",
    "                    'Chip Transaction', 'Is Fraud?']\n",
    "\n",
    "users = pd.read_csv('./Data/FinalData/users.csv', usecols=users_needed_cols, dtype=types['users'])\n",
    "cards = pd.read_csv('./Data/FinalData/cards.csv', usecols=cards_needed_cols, dtype=types['cards'])\n",
    "trans = pd.read_csv('./Data/FinalData/trans.csv', usecols=trans_needed_cols, dtype=types['trans'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Transactions Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 5\n",
    "seq_len = 10\n",
    "trans_df = []\n",
    "targets = []\n",
    "trans_feats = [\n",
    "    'Time', 'Time From Now', 'Amount', 'Merchant Name', 'Merchant City', 'Merchant State', \n",
    "    'Zip', 'MCC', 'Errors?', 'Swipe Transaction', 'Online Transaction', 'Chip Transaction'\n",
    "]\n",
    "user_card_dict = trans.groupby('User')['Card'].unique().to_dict()\n",
    "\n",
    "for user_id in tqdm(user_card_dict.keys()):\n",
    "    for card_id in user_card_dict[user_id]:\n",
    "        t_df = trans[(trans['User'] == user_id) & (trans['Card'] == card_id)]\n",
    "        for i in range(0, t_df.shape[0], stride):\n",
    "            wind_df = t_df[i:i+seq_len]\n",
    "            trans_df.append((user_id, card_id, wind_df[trans_feats]))\n",
    "            targets.append(wind_df['Is Fraud?'].iloc[-1])\n",
    "joblib.dump(trans_df, '/content/drive/MyDrive/IBM_Dataset/trans_df.pkl')\n",
    "joblib.dump(targets, '/content/drive/MyDrive/IBM_Dataset/targets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(trans_df, targets, test_size=0.3, random_state=42, stratify=targets)\n",
    "x_train, x_val, y_train, y_val = train_test_split(trans_df, targets, test_size=0.1, random_state=42, stratify=targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "n_step = 10\n",
    "users_feats = 9\n",
    "cards_feats = 14\n",
    "trans_feats = 12\n",
    "n_feats = users_feats + cards_feats + trans_feats\n",
    "n_feats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(user_df: pd.DataFrame, card_df: pd.DataFrame, trans_df: list, target: list, batch_size: int, conv_input=False):\n",
    "    card_df.set_index(['User', 'CARD INDEX'], inplace=True)\n",
    "    while True:\n",
    "        idx = np.random.choice(range(len(trans_df)), size=len(trans_df), replace=False)\n",
    "        for i in range(0, len(idx), batch_size):\n",
    "            t_df = [trans_df[idx[j]] for j in range(i, i + batch_size)]\n",
    "            X = np.zeros((len(t_df), n_step, n_feats))\n",
    "            Y = np.array([targets[idx[j]] for j in range(i, i + batch_size)])\n",
    "\n",
    "            for it, (user_id, card_id, wind_df) in enumerate(t_df):\n",
    "                user = user_df.iloc[user_id]\n",
    "                card = card_df.loc[[user_id, card_id]]\n",
    "                x = pd.concat([user, card, wind_df], axis=1).ffill().values\n",
    "                X[it] = x\n",
    "            if conv_input:\n",
    "                X = np.transpose(X, axis=[0, 2, 1])\n",
    "            yield X, Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
    "        :param history: Training history of model\n",
    "        :return:\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(4)\n",
    "    fig.tight_layout(pad=3)\n",
    "\n",
    "    axs[0].plot(history.history[\"loss\"], label=\"train loss\")\n",
    "    axs[0].plot(history.history[\"val_loss\"], label=\"val loss\")\n",
    "    axs[0].set_ylabel(\"loss\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].legend(loc=\"upper right\")\n",
    "    axs[0].set_title(\"Loss\")\n",
    "\n",
    "    axs[1].plot(history.history[\"auc\"], label=\"train AUC\")\n",
    "    axs[1].plot(history.history[\"val_auc\"], label=\"val AUC\")\n",
    "    axs[1].set_ylabel(\"AUC\")\n",
    "    axs[1].legend(loc=\"lower right\")\n",
    "    axs[1].set_title(\"AUC\")\n",
    "\n",
    "    axs[2].plot(history.history[\"precision\"], label=\"train precision\")\n",
    "    axs[2].plot(history.history[\"val_precision\"], label=\"val precision\")\n",
    "    axs[2].set_ylabel(\"Precision\")\n",
    "    axs[2].legend(loc=\"lower right\")\n",
    "    axs[2].set_title(\"Precision\")\n",
    "\n",
    "    axs[3].plot(history.history[\"recall\"], label=\"train recall\")\n",
    "    axs[3].plot(history.history[\"val_recall\"], label=\"val recall\")\n",
    "    axs[3].set_ylabel(\"Recall\")\n",
    "    axs[3].legend(loc=\"lower right\")\n",
    "    axs[3].set_title(\"Recall\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LstmModel():\n",
    "  model = keras.Sequential()\n",
    "  \n",
    "  model.add(layers.LSTM(units=64, kernel_regularizer='l2', return_sequences=True, time_major=False, input_shape=(n_step, n_feats)))\n",
    "  model.add(layers.LSTM(units=32, kernel_regularizer='l2', return_sequences=True, time_major=False))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LSTM(units=16, kernel_regularizer='l2', return_sequences=False, time_major=False))\n",
    "  model.add(layers.Dense(16))\n",
    "  model.add(layers.Dropout(0.2))\n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GruModel():\n",
    "  model = keras.Sequential()\n",
    "  \n",
    "  model.add(layers.GRU(units=64, kernel_regularizer='l2', return_sequences=True, time_major=False, input_shape=(n_step, n_feats)))\n",
    "  model.add(layers.GRU(units=32, kernel_regularizer='l2', return_sequences=True, time_major=False))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.GRU(units=16, kernel_regularizer='l2', return_sequences=False, time_major=False))\n",
    "  model.add(layers.Dense(16))\n",
    "  model.add(layers.Dropout(0.2))\n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvModel():\n",
    "  model = keras.Sequential()\n",
    "  \n",
    "  model.add(layers.Conv1D(64, 3, activation='relu', kernel_regularizer='l2', input_shape=(n_feats, n_step)))\n",
    "  model.add(layers.AveragePooling1D(pool_size=2, strides=2))\n",
    "  model.add(layers.Conv1D(128, 7, activation='relu', kernel_regularizer='l2'))\n",
    "  model.add(layers.Conv1D(512, 5, activation='relu', kernel_regularizer='l2'))\n",
    "  model.add(layers.Conv1D(1024, 5, activation='relu', kernel_regularizer='l2'))\n",
    "  model.add(layers.AveragePooling1D(pool_size=2))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(256))\n",
    "  model.add(layers.Dropout(0.3))\n",
    "  model.add(layers.Dense(128))\n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvLstmModel():\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  model.add(layers.Conv1D(64, 3, activation='relu', kernel_regularizer='l2', input_shape=(n_feats, n_step)))\n",
    "  model.add(layers.AveragePooling1D(pool_size=2, strides=2))\n",
    "  model.add(layers.Conv1D(128, 3, activation='relu', kernel_regularizer='l2'))\n",
    "  model.add(layers.Conv1D(512, 5, activation='relu', kernel_regularizer='l2'))\n",
    "  model.add(layers.Conv1D(1024, 5, activation='relu', kernel_regularizer='l2'))\n",
    "\n",
    "  model.add(layers.Dense(256))\n",
    "  model.add(layers.Dropout(0.3))\n",
    "\n",
    "  model.add(layers.LSTM(64, kernel_regularizer='l2',  return_sequences=True))\n",
    "  model.add(layers.LSTM(64, kernel_regularizer='l2',  return_sequences=False))\n",
    "  \n",
    "  model.add(layers.Dense(256))\n",
    "  model.add(layers.Dense(128))\n",
    "  model.add(layers.Dense(1, activation='sigmoid'))\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvAE():\n",
    "    input = layers.Input(shape=(n_feats, n_step))\n",
    "    x = layers.Conv1D(64, 3, strides=2, activation='relu', kernel_regularizer='l2')(input)\n",
    "    x = layers.Conv1D(128, 5, strides=2, activation='relu', kernel_regularizer='l2')(x)\n",
    "    x = layers.AveragePooling1D(4)(x)\n",
    "    y = layers.Conv1DTranspose(128, 1, strides=7, activation='relu', kernel_regularizer='l2')(x)\n",
    "    y = layers.Conv1DTranspose(64, 5, strides=2, activation='relu', kernel_regularizer='l2')(y)\n",
    "    y = layers.Conv1DTranspose(10, 3, strides=2, activation='relu', kernel_regularizer='l2')(y)\n",
    "    encoder = Model(inputs=input, outputs=x)\n",
    "    ae = Model(inputs=input, outputs=y)\n",
    "    return ae"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LstmAE():\n",
    "    input = layers.Input(shape=(n_step, n_feats))\n",
    "    x = layers.LSTM(units=64, kernel_regularizer='l2', return_sequences=True)(input)\n",
    "    x = layers.LSTM(units=32, kernel_regularizer='l2', return_sequences=False)(x)\n",
    "    y = layers.RepeatVector(n_step)(x)\n",
    "    y = layers.LSTM(units=32, kernel_regularizer='l2', return_sequences=True)(y)\n",
    "    y = layers.LSTM(units=64, kernel_regularizer='l2', return_sequences=True)(y)\n",
    "    output = layers.TimeDistributed(layers.Dense(n_feats))(y)\n",
    "    encoder = Model(inputs=input, outputs=x)\n",
    "    ae = Model(inputs=input, outputs=output)\n",
    "    return ae, encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    model = None\n",
    "    if model_name == 'LSTM':\n",
    "        model = LstmModel()\n",
    "    elif model_name == 'GRU':\n",
    "        model = GruModel()\n",
    "    elif model_name == 'CONV':\n",
    "        model = ConvModel()\n",
    "    elif model_name == 'CONVLSTM':\n",
    "        model = ConvLstmModel()\n",
    "    elif model_name == 'CONVAE':\n",
    "        model = ConvAE()\n",
    "    elif model_name == 'LSTMAE':\n",
    "        model = LstmAE()\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 20\n",
    "weight_decay = 0.0\n",
    "checkpoint_dir = '/content/drive/MyDrive/IBM_Dataset/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ''\n",
    "model = get_model(model_name)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0, 1], y=targets)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_batch(users, cards, x_train, y_train, batch_size, True if model_name in {'CONV', 'CONVLSTM', 'CONVAE'} else False)\n",
    "val_loader = get_batch(users, cards, x_val, y_val, batch_size, True if model_name in {'CONV', 'CONVLSTM', 'CONVAE'} else False)\n",
    "test_loader = get_batch(users, cards, x_test, y_test, batch_size, True if model_name in {'CONV', 'CONVLSTM', 'CONVAE'} else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr, weight_decay=weight_decay), \n",
    "    loss='binary_crossentropy',\n",
    "    loss_weights=class_weights,\n",
    "    metrics=[keras.metrics.AUC()],\n",
    "    weighted_metrics=[keras.metrics.Precision(), keras.metrics.Recall()]\n",
    ")\n",
    "train_details = model.fit(\n",
    "    x=train_loader,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_loader,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, monitor='val_loss'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(checkpoint_dir, model_name), monitor='val_loss', save_best_only=True)\n",
    "    ],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79af883d0fed3fde69702b9c6d67210ea7fab711f741cf74fe3ad86041e7d3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
